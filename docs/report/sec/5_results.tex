\section{Results and Discussion}
\label{sec:results}
We summarize the key findings from applying our framework to the CMAPSS datasets, focusing on results derived using KMeans clustering for stage definition.

\subsection{Clustering and Stage Definition}
KMeans successfully identified 5 distinct operational stages based on sensor data patterns, corroborated by RUL averages and visual inspection of sensor trends (\cref{fig:sensor_trends_cluster}) and PCA plots (\cref{fig:cluster_pca}). While clear separation was observed in some datasets (e.g., FD002/FD004), others exhibited overlap between intermediate stages (e.g., FD001), reflecting degradation's continuous nature. A significant class imbalance was observed, with most data points belonging to healthier stages (Stage 0/1) - for FD001, approximately 65\% of data points were in Stage 0, 20\% in Stage 1, 8\% in Stage 2, 5\% in Stage 3, and 2\% in Stage 4.

\subsection{Classification Performance}
Predicting the derived `kmeans\_stage` was feasible, with Logistic Regression (using SMOTE or class weighting) achieving competitive performance across datasets (see Table~\ref{tab:classification_results} for full metrics). Key results include:
\begin{itemize}
	\item Macro F1 scores averaged 0.78 and Weighted F1 scores averaged 0.87 across all datasets and best models.
	\item Imbalance handling significantly improved recall for minority failure stages (3 and 4), achieving an average Stage 4 F1-score of 0.83.
	\item Confusion matrices (\cref{fig:confusion_matrix}) confirmed most errors occurred between adjacent stages, supporting the validity of our stage definition approach.
\end{itemize}

\subsection{Regression Performance}
Predicting the `time\_to\_next\_stage` yielded moderate results. Best models (typically Ridge or XGBoost) achieved average RMSEs around 12.6 cycles and RÂ² scores around 0.74 (Table~\ref{tab:regression_results}). Diagnostic plots (\cref{fig:actual_vs_pred}, \cref{fig:residuals}) indicated reasonable fit but also highlighted the difficulty in precise temporal prediction, especially further from the transition point. Performance varied across datasets, with FD001 (single operational condition, single fault mode) showing better predictability than more complex scenarios.

\subsection{Risk Score Analysis}
The Risk Score, calculated using the severity\_product formula and normalized, provided a dynamic indicator of engine health. Trend plots (\cref{fig:risk_score_trend}) showed the score consistently increasing as engines approached failure. Applying an alert threshold $\theta = 0.7$ allowed for identifying high-risk operational points, demonstrating the score's potential for triggering maintenance actions based on combined probability and severity/urgency assessment. The score exhibited favorable early warning properties, typically rising above threshold 15-30 cycles before failure.

\subsection{Discussion Summary}
The hybrid approach successfully generated granular, data-driven degradation stages and used them for both state classification and temporal prediction. While challenges like class imbalance and regression accuracy exist, the framework offers a more nuanced view than traditional RUL methods. The Risk Score provides a practical way to synthesize model outputs for decision support.

Several limitations deserve mention: (1) reliance on simulation data may not capture real-world complexities; (2) framework performance depends significantly on clustering quality; (3) stage transitions can be somewhat arbitrary in continuous degradation processes; and (4) additional sensor types could potentially improve discrimination between intermediate stages. Future work should address these limitations and validate the approach on real-world maintenance data.
